{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning using Keras in Python : Customer Churn Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the targeted approach the company tries to identify in advance customers who are likely to churn. The company then targets those customers with special programs or incentives. This approach can bring in huge loss for a company, if churn predictions are inaccurate, because then firms are wasting incentive money on customers who would have stayed anyway. There are numerous predictive modeling techniques for predicting customer churn.\n",
    "\n",
    "The data files state that the data are \"artificial based on claims similar to real world\". These data are also contained in the C50 R package.\n",
    "\n",
    "Data and associated files are also available at: http://www.sgi.com/tech/mlc/db/churn.data\n",
    "\n",
    "The analysis is done in Keras library in Python. The task is to predict whether the customer will churn or not, using the given features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start off by importing the libraries in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read the dataset from the url and view it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "custchurn = pd.read_csv(\"http://www.sgi.com/tech/mlc/db/churn.data\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AL</td>\n",
       "      <td>118</td>\n",
       "      <td>510</td>\n",
       "      <td>391-8027</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>223.4</td>\n",
       "      <td>98</td>\n",
       "      <td>37.98</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>18.75</td>\n",
       "      <td>203.9</td>\n",
       "      <td>118</td>\n",
       "      <td>9.18</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MA</td>\n",
       "      <td>121</td>\n",
       "      <td>510</td>\n",
       "      <td>355-9993</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>218.2</td>\n",
       "      <td>88</td>\n",
       "      <td>37.09</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>29.62</td>\n",
       "      <td>212.6</td>\n",
       "      <td>118</td>\n",
       "      <td>9.57</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MO</td>\n",
       "      <td>147</td>\n",
       "      <td>415</td>\n",
       "      <td>329-9001</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>79</td>\n",
       "      <td>26.69</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>8.76</td>\n",
       "      <td>211.8</td>\n",
       "      <td>96</td>\n",
       "      <td>9.53</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LA</td>\n",
       "      <td>117</td>\n",
       "      <td>408</td>\n",
       "      <td>335-4719</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>184.5</td>\n",
       "      <td>97</td>\n",
       "      <td>31.37</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>29.89</td>\n",
       "      <td>215.8</td>\n",
       "      <td>90</td>\n",
       "      <td>9.71</td>\n",
       "      <td>8.7</td>\n",
       "      <td>4</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WV</td>\n",
       "      <td>141</td>\n",
       "      <td>415</td>\n",
       "      <td>330-8173</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>258.6</td>\n",
       "      <td>84</td>\n",
       "      <td>43.96</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>18.87</td>\n",
       "      <td>326.4</td>\n",
       "      <td>97</td>\n",
       "      <td>14.69</td>\n",
       "      <td>11.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2          3     4     5   6      7    8      9    ...      11  \\\n",
       "0  KS  128  415   382-4657    no   yes  25  265.1  110  45.07   ...      99   \n",
       "1  OH  107  415   371-7191    no   yes  26  161.6  123  27.47   ...     103   \n",
       "2  NJ  137  415   358-1921    no    no   0  243.4  114  41.38   ...     110   \n",
       "3  OH   84  408   375-9999   yes    no   0  299.4   71  50.90   ...      88   \n",
       "4  OK   75  415   330-6626   yes    no   0  166.7  113  28.34   ...     122   \n",
       "5  AL  118  510   391-8027   yes    no   0  223.4   98  37.98   ...     101   \n",
       "6  MA  121  510   355-9993    no   yes  24  218.2   88  37.09   ...     108   \n",
       "7  MO  147  415   329-9001   yes    no   0  157.0   79  26.69   ...      94   \n",
       "8  LA  117  408   335-4719    no    no   0  184.5   97  31.37   ...      80   \n",
       "9  WV  141  415   330-8173   yes   yes  37  258.6   84  43.96   ...     111   \n",
       "\n",
       "      12     13   14     15    16  17    18  19       20  \n",
       "0  16.78  244.7   91  11.01  10.0   3  2.70   1   False.  \n",
       "1  16.62  254.4  103  11.45  13.7   3  3.70   1   False.  \n",
       "2  10.30  162.6  104   7.32  12.2   5  3.29   0   False.  \n",
       "3   5.26  196.9   89   8.86   6.6   7  1.78   2   False.  \n",
       "4  12.61  186.9  121   8.41  10.1   3  2.73   3   False.  \n",
       "5  18.75  203.9  118   9.18   6.3   6  1.70   0   False.  \n",
       "6  29.62  212.6  118   9.57   7.5   7  2.03   3   False.  \n",
       "7   8.76  211.8   96   9.53   7.1   6  1.92   0   False.  \n",
       "8  29.89  215.8   90   9.71   8.7   4  2.35   1   False.  \n",
       "9  18.87  326.4   97  14.69  11.2   5  3.02   0   False.  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custchurn.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is in a very usable format. Check for NA's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I : Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 21 columns):\n",
      "0     3333 non-null object\n",
      "1     3333 non-null int64\n",
      "2     3333 non-null int64\n",
      "3     3333 non-null object\n",
      "4     3333 non-null object\n",
      "5     3333 non-null object\n",
      "6     3333 non-null int64\n",
      "7     3333 non-null float64\n",
      "8     3333 non-null int64\n",
      "9     3333 non-null float64\n",
      "10    3333 non-null float64\n",
      "11    3333 non-null int64\n",
      "12    3333 non-null float64\n",
      "13    3333 non-null float64\n",
      "14    3333 non-null int64\n",
      "15    3333 non-null float64\n",
      "16    3333 non-null float64\n",
      "17    3333 non-null int64\n",
      "18    3333 non-null float64\n",
      "19    3333 non-null int64\n",
      "20    3333 non-null object\n",
      "dtypes: float64(8), int64(8), object(5)\n",
      "memory usage: 546.9+ KB\n"
     ]
    }
   ],
   "source": [
    "custchurn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assign the column names from the description and give a random shuffle to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>churned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MS</td>\n",
       "      <td>140</td>\n",
       "      <td>408</td>\n",
       "      <td>372-5262</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>162.6</td>\n",
       "      <td>98</td>\n",
       "      <td>27.64</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>17.53</td>\n",
       "      <td>141.6</td>\n",
       "      <td>66</td>\n",
       "      <td>6.37</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WY</td>\n",
       "      <td>16</td>\n",
       "      <td>415</td>\n",
       "      <td>400-3197</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>174.7</td>\n",
       "      <td>83</td>\n",
       "      <td>29.70</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>23.87</td>\n",
       "      <td>171.7</td>\n",
       "      <td>80</td>\n",
       "      <td>7.73</td>\n",
       "      <td>10.5</td>\n",
       "      <td>8</td>\n",
       "      <td>2.84</td>\n",
       "      <td>5</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IN</td>\n",
       "      <td>130</td>\n",
       "      <td>408</td>\n",
       "      <td>334-9818</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>129</td>\n",
       "      <td>19.65</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>14.26</td>\n",
       "      <td>141.8</td>\n",
       "      <td>124</td>\n",
       "      <td>6.38</td>\n",
       "      <td>12.6</td>\n",
       "      <td>9</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VA</td>\n",
       "      <td>121</td>\n",
       "      <td>415</td>\n",
       "      <td>357-7064</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>134.1</td>\n",
       "      <td>112</td>\n",
       "      <td>22.80</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>16.58</td>\n",
       "      <td>159.6</td>\n",
       "      <td>139</td>\n",
       "      <td>7.18</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OH</td>\n",
       "      <td>56</td>\n",
       "      <td>408</td>\n",
       "      <td>349-2654</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>91.1</td>\n",
       "      <td>90</td>\n",
       "      <td>15.49</td>\n",
       "      <td>...</td>\n",
       "      <td>115</td>\n",
       "      <td>15.24</td>\n",
       "      <td>300.7</td>\n",
       "      <td>89</td>\n",
       "      <td>13.53</td>\n",
       "      <td>11.9</td>\n",
       "      <td>8</td>\n",
       "      <td>3.21</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VT</td>\n",
       "      <td>43</td>\n",
       "      <td>408</td>\n",
       "      <td>331-8713</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>135.8</td>\n",
       "      <td>125</td>\n",
       "      <td>23.09</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>13.87</td>\n",
       "      <td>229.8</td>\n",
       "      <td>106</td>\n",
       "      <td>10.34</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SC</td>\n",
       "      <td>130</td>\n",
       "      <td>415</td>\n",
       "      <td>396-4410</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>212.8</td>\n",
       "      <td>102</td>\n",
       "      <td>36.18</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>16.13</td>\n",
       "      <td>170.1</td>\n",
       "      <td>105</td>\n",
       "      <td>7.65</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CT</td>\n",
       "      <td>37</td>\n",
       "      <td>408</td>\n",
       "      <td>347-7675</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>134.9</td>\n",
       "      <td>98</td>\n",
       "      <td>22.93</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>21.11</td>\n",
       "      <td>236.2</td>\n",
       "      <td>113</td>\n",
       "      <td>10.63</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2</td>\n",
       "      <td>3.97</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OH</td>\n",
       "      <td>127</td>\n",
       "      <td>408</td>\n",
       "      <td>396-9462</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>139.6</td>\n",
       "      <td>94</td>\n",
       "      <td>23.73</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>20.48</td>\n",
       "      <td>127.1</td>\n",
       "      <td>88</td>\n",
       "      <td>5.72</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OK</td>\n",
       "      <td>138</td>\n",
       "      <td>510</td>\n",
       "      <td>406-5532</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>33</td>\n",
       "      <td>155.2</td>\n",
       "      <td>139</td>\n",
       "      <td>26.38</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>22.81</td>\n",
       "      <td>186.4</td>\n",
       "      <td>71</td>\n",
       "      <td>8.39</td>\n",
       "      <td>9.7</td>\n",
       "      <td>4</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account_length  area_code phone_number international_plan  \\\n",
       "0    MS             140        408     372-5262                 no   \n",
       "1    WY              16        415     400-3197                 no   \n",
       "2    IN             130        408     334-9818                 no   \n",
       "3    VA             121        415     357-7064                 no   \n",
       "4    OH              56        408     349-2654                 no   \n",
       "5    VT              43        408     331-8713                 no   \n",
       "6    SC             130        415     396-4410                 no   \n",
       "7    CT              37        408     347-7675                 no   \n",
       "8    OH             127        408     396-9462                 no   \n",
       "9    OK             138        510     406-5532                 no   \n",
       "\n",
       "  voice_mail_plan  number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0              no                      0              162.6               98   \n",
       "1              no                      0              174.7               83   \n",
       "2              no                      0              115.6              129   \n",
       "3              no                      0              134.1              112   \n",
       "4              no                      0               91.1               90   \n",
       "5              no                      0              135.8              125   \n",
       "6              no                      0              212.8              102   \n",
       "7              no                      0              134.9               98   \n",
       "8              no                      0              139.6               94   \n",
       "9             yes                     33              155.2              139   \n",
       "\n",
       "   total_day_charge   ...     total_eve_calls  total_eve_charge  \\\n",
       "0             27.64   ...                 109             17.53   \n",
       "1             29.70   ...                 122             23.87   \n",
       "2             19.65   ...                 104             14.26   \n",
       "3             22.80   ...                 104             16.58   \n",
       "4             15.49   ...                 115             15.24   \n",
       "5             23.09   ...                  88             13.87   \n",
       "6             36.18   ...                 137             16.13   \n",
       "7             22.93   ...                 130             21.11   \n",
       "8             23.73   ...                 112             20.48   \n",
       "9             26.38   ...                  79             22.81   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                141.6                 66                6.37   \n",
       "1                171.7                 80                7.73   \n",
       "2                141.8                124                6.38   \n",
       "3                159.6                139                7.18   \n",
       "4                300.7                 89               13.53   \n",
       "5                229.8                106               10.34   \n",
       "6                170.1                105                7.65   \n",
       "7                236.2                113               10.63   \n",
       "8                127.1                 88                5.72   \n",
       "9                186.4                 71                8.39   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 8.2                 2               2.21   \n",
       "1                10.5                 8               2.84   \n",
       "2                12.6                 9               3.40   \n",
       "3                10.5                 2               2.84   \n",
       "4                11.9                 8               3.21   \n",
       "5                12.6                 3               3.40   \n",
       "6                10.6                 4               2.86   \n",
       "7                14.7                 2               3.97   \n",
       "8                 8.8                 4               2.38   \n",
       "9                 9.7                 4               2.62   \n",
       "\n",
       "   number_customer_service_calls  churned  \n",
       "0                              1   False.  \n",
       "1                              5   False.  \n",
       "2                              1   False.  \n",
       "3                              2   False.  \n",
       "4                              2   False.  \n",
       "5                              0   False.  \n",
       "6                              0    True.  \n",
       "7                              3   False.  \n",
       "8                              2   False.  \n",
       "9                              3   False.  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custchurn.columns = [\"state\",\"account_length\",\"area_code\",\"phone_number\",\"international_plan\",\"voice_mail_plan\",\"number_vmail_messages\",\"total_day_minutes\",\"total_day_calls\",\"total_day_charge\",\"total_eve_minutes\",\"total_eve_calls\",\"total_eve_charge\",\"total_night_minutes\",\"total_night_calls\",\"total_night_charge\",\"total_intl_minutes\",\"total_intl_calls\",\"total_intl_charge\",\"number_customer_service_calls\",\"churned\"]\n",
    "custchurn = custchurn.sample(frac=1).reset_index(drop=True)\n",
    "custchurn.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature vector and target vector \n",
    "\n",
    "Now create the feature vectors, avoiding 'state', 'area_code','phone_number'. The target vector is the 'churned' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = custchurn.iloc[:,[1,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]].values\n",
    "y = custchurn.iloc[:,20].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features\n",
    "\n",
    "We have categorical features,'international_plan', 'voice_mail_plan' and 'churned'.Encode them into numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:,1] = labelencoder_X_1.fit_transform(X[:,1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:,2] = labelencoder_X_2.fit_transform(X[:,2])\n",
    "# Encoding Target variable 'churned'\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is absolutely necessary to do feature scaling for neural networks because its computationally intensive !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II : Building the Artificial Neural Network\n",
    "\n",
    "We build the ANN with the Keras library in Python. Also we import the class 'Sequential' for initializing the network as a sequence of layers and the class 'Dense' for building actual layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential # initialize ANN\n",
    "from keras.layers import Dense # build layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "# Defining ANN as a sequence of layers\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are building one input layer with 17 neurons corresponding to the 17 input features and two hidden layers with 9 neurons in it. The problem being a binary classification, ouput layer has only one neuron. No. of neurons in hidden layer may be calculated as : (17+1)/2 =9\n",
    "\n",
    "Also, lets use the activation function 'recifier' for input and hidden layers and 'sigmoid' function for the ouput layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "# rectifier act. fun for hidden layers\n",
    "classifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'relu', input_dim = 17))\n",
    "# output_dim = no of nodes in hidden layer = (17+1)/2 =9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "# sigmoid act. function for output layers\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compile the ANN using the optimizer 'adam', loss function, 'binary_crossentropy with the accuracy as the evaluation parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having compliled the ANN, lets now fit the ANN based learning to our training set, in batches of 10, for 100 epochs/iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.5167 - acc: 0.8548     \n",
      "Epoch 2/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3380 - acc: 0.8556     \n",
      "Epoch 3/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3289 - acc: 0.8556     \n",
      "Epoch 4/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3251 - acc: 0.8556     \n",
      "Epoch 5/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3225 - acc: 0.8556     \n",
      "Epoch 6/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3198 - acc: 0.8556     \n",
      "Epoch 7/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3185 - acc: 0.8605     \n",
      "Epoch 8/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3174 - acc: 0.8650     \n",
      "Epoch 9/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3160 - acc: 0.8683     \n",
      "Epoch 10/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3155 - acc: 0.8683     \n",
      "Epoch 11/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3141 - acc: 0.8713     \n",
      "Epoch 12/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3133 - acc: 0.8698     \n",
      "Epoch 13/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3125 - acc: 0.8706     \n",
      "Epoch 14/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3108 - acc: 0.8743     \n",
      "Epoch 15/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3098 - acc: 0.8751     \n",
      "Epoch 16/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3095 - acc: 0.8755     \n",
      "Epoch 17/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3091 - acc: 0.8713     \n",
      "Epoch 18/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3074 - acc: 0.8755     \n",
      "Epoch 19/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3070 - acc: 0.8728     \n",
      "Epoch 20/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3062 - acc: 0.8751     \n",
      "Epoch 21/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3057 - acc: 0.8751     \n",
      "Epoch 22/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3045 - acc: 0.8770     \n",
      "Epoch 23/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3037 - acc: 0.8758     \n",
      "Epoch 24/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3036 - acc: 0.8792     \n",
      "Epoch 25/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3027 - acc: 0.8766     \n",
      "Epoch 26/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3018 - acc: 0.8788     \n",
      "Epoch 27/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.3005 - acc: 0.8770     \n",
      "Epoch 28/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2993 - acc: 0.8785     \n",
      "Epoch 29/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2966 - acc: 0.8792     \n",
      "Epoch 30/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2945 - acc: 0.8848     \n",
      "Epoch 31/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2893 - acc: 0.8882     \n",
      "Epoch 32/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2760 - acc: 0.8968     \n",
      "Epoch 33/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2601 - acc: 0.9021     \n",
      "Epoch 34/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2446 - acc: 0.9107     \n",
      "Epoch 35/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2330 - acc: 0.9145     \n",
      "Epoch 36/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2248 - acc: 0.9197     \n",
      "Epoch 37/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2176 - acc: 0.9272     \n",
      "Epoch 38/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2133 - acc: 0.9295     \n",
      "Epoch 39/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2105 - acc: 0.9291     \n",
      "Epoch 40/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2069 - acc: 0.9325     \n",
      "Epoch 41/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2045 - acc: 0.9332     \n",
      "Epoch 42/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2030 - acc: 0.9347     \n",
      "Epoch 43/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2016 - acc: 0.9381     \n",
      "Epoch 44/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.2004 - acc: 0.9396     \n",
      "Epoch 45/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1986 - acc: 0.9389     \n",
      "Epoch 46/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1967 - acc: 0.9407     \n",
      "Epoch 47/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1952 - acc: 0.9419     \n",
      "Epoch 48/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1933 - acc: 0.9404     \n",
      "Epoch 49/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1926 - acc: 0.9430     \n",
      "Epoch 50/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1912 - acc: 0.9441     \n",
      "Epoch 51/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1902 - acc: 0.9449     \n",
      "Epoch 52/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1893 - acc: 0.9460     \n",
      "Epoch 53/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1879 - acc: 0.9464     \n",
      "Epoch 54/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1879 - acc: 0.9426     \n",
      "Epoch 55/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1868 - acc: 0.9460     \n",
      "Epoch 56/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1851 - acc: 0.9479     \n",
      "Epoch 57/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1848 - acc: 0.9452     \n",
      "Epoch 58/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1838 - acc: 0.9460     \n",
      "Epoch 59/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1840 - acc: 0.9456     \n",
      "Epoch 60/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1832 - acc: 0.9471     \n",
      "Epoch 61/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1802 - acc: 0.9452     \n",
      "Epoch 62/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1805 - acc: 0.9482     \n",
      "Epoch 63/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1793 - acc: 0.9452     \n",
      "Epoch 64/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1796 - acc: 0.9460     \n",
      "Epoch 65/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1792 - acc: 0.9464     \n",
      "Epoch 66/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1780 - acc: 0.9467     \n",
      "Epoch 67/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1778 - acc: 0.9471     \n",
      "Epoch 68/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1769 - acc: 0.9486     \n",
      "Epoch 69/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1761 - acc: 0.9467     \n",
      "Epoch 70/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1753 - acc: 0.9475     \n",
      "Epoch 71/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1741 - acc: 0.9494     \n",
      "Epoch 72/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1727 - acc: 0.9475     \n",
      "Epoch 73/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1723 - acc: 0.9479     \n",
      "Epoch 74/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1716 - acc: 0.9490     \n",
      "Epoch 75/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1721 - acc: 0.9486     \n",
      "Epoch 76/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1700 - acc: 0.9486     \n",
      "Epoch 77/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1703 - acc: 0.9486     \n",
      "Epoch 78/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1692 - acc: 0.9471     \n",
      "Epoch 79/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1698 - acc: 0.9482     \n",
      "Epoch 80/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1695 - acc: 0.9490     \n",
      "Epoch 81/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1679 - acc: 0.9490     \n",
      "Epoch 82/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1674 - acc: 0.9539     \n",
      "Epoch 83/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1676 - acc: 0.9479     \n",
      "Epoch 84/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1667 - acc: 0.9497     \n",
      "Epoch 85/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1671 - acc: 0.9475     \n",
      "Epoch 86/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1654 - acc: 0.9501     \n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2666/2666 [==============================] - 0s - loss: 0.1666 - acc: 0.9509     \n",
      "Epoch 88/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1647 - acc: 0.9501     \n",
      "Epoch 89/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1649 - acc: 0.9509     \n",
      "Epoch 90/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1645 - acc: 0.9501     \n",
      "Epoch 91/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1628 - acc: 0.9524     \n",
      "Epoch 92/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1631 - acc: 0.9497     \n",
      "Epoch 93/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1623 - acc: 0.9501     \n",
      "Epoch 94/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1639 - acc: 0.9490     \n",
      "Epoch 95/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1648 - acc: 0.9494     \n",
      "Epoch 96/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1618 - acc: 0.9527     \n",
      "Epoch 97/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1613 - acc: 0.9512     \n",
      "Epoch 98/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1619 - acc: 0.9527     \n",
      "Epoch 99/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1606 - acc: 0.9539     \n",
      "Epoch 100/100\n",
      "2666/2666 [==============================] - 0s - loss: 0.1607 - acc: 0.9479     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1293990b8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III : Making the predictions and evaluating the model\n",
    "\n",
    "We now make predictions using the predict method and print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5) #important step here\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[563,   6],\n",
       "       [ 32,  66]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94302848575712139"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cm[0,0]+cm[1,1])/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concluding Remarks\n",
    "\n",
    "1. The Deep Learning classifier has an accuracy of 94.3 % on the test set. It is a good range for the dataset, but we can still improve the accuracy by adding more hidden layers and training for more number of epochs\n",
    "\n",
    "2. Statistical significance tests may be performed to find the relevant variables for the case\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
