{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks/LSTM's for financial time series predictions\n",
    "\n",
    "Recurrent neural networks, or RNNs, are a type of artificial neural network that add additional weights to the network to create cycles in the network graph in an effort to maintain an internal state.The promise of adding state to neural networks is that they will be able to explicitly learn and exploit context in sequence prediction problems, such as problems with an order or temporal component. In A Recurrent Neural Network each unit/node remebers what was there in the previous unit/node and hence well suited for time series predictions. The architecture is so designed that recurring weights are used to connect hidden layers among themselves. This can infact bring about `vanishing gradient` problem in RNN's. A practical solution to it being the Long Short Term Memory Networks (LSTM's) and its typical architecture. LSTM's find significant applications today in language translation apps, sentiment analysis and so on.\n",
    "\n",
    "This project uses LSTM's for predicting financial market time series prediction i.e with Google Stock Prices.The RNN will be trained on data on working days from from January 2012 to December 2016, over a period of 5 years and then will be tested to predict stock prices for the month of January 2017. The dataset can be extracted from : https://finance.google.com/finance/historical?q=GOOG\n",
    "\n",
    "The implementation is done using the Keras library in Python using Tensorflow backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets begin by importing the libraries and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training set\n",
    "dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now lets preview the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/10/2012</td>\n",
       "      <td>313.70</td>\n",
       "      <td>315.72</td>\n",
       "      <td>307.30</td>\n",
       "      <td>621.43</td>\n",
       "      <td>8,824,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/11/2012</td>\n",
       "      <td>310.59</td>\n",
       "      <td>313.52</td>\n",
       "      <td>309.40</td>\n",
       "      <td>624.25</td>\n",
       "      <td>4,817,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>314.43</td>\n",
       "      <td>315.26</td>\n",
       "      <td>312.08</td>\n",
       "      <td>627.92</td>\n",
       "      <td>3,764,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/13/2012</td>\n",
       "      <td>311.96</td>\n",
       "      <td>312.30</td>\n",
       "      <td>309.37</td>\n",
       "      <td>623.28</td>\n",
       "      <td>4,631,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/17/2012</td>\n",
       "      <td>314.81</td>\n",
       "      <td>314.81</td>\n",
       "      <td>311.67</td>\n",
       "      <td>626.86</td>\n",
       "      <td>3,832,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Open    High     Low   Close      Volume\n",
       "0   1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1   1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2   1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3   1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4   1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n",
       "5  1/10/2012  313.70  315.72  307.30  621.43   8,824,000\n",
       "6  1/11/2012  310.59  313.52  309.40  624.25   4,817,800\n",
       "7  1/12/2012  314.43  315.26  312.08  627.92   3,764,400\n",
       "8  1/13/2012  311.96  312.30  309.37  623.28   4,631,800\n",
       "9  1/17/2012  314.81  314.81  311.67  626.86   3,832,800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is in a very usable format with no NA's. The data has 1258 rows.\n",
    "\n",
    "We will be building RNN's to predict the Open Google stock prices  and so we will retain the first column only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = dataset_train.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature Scaling\n",
    "\n",
    "Feature scaling is a must to do in Deep Learning. Here MinMaxScaler is used for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating a data structure with 60 timesteps and t+1 output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For setting timestep 60, we need to create an X_train numpy array with 1258-60 =1198 rows and each with 60 elements from training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 60 timesteps and t+1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 1258):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reshaping\n",
    "We need to create a 3D array for processing with Keras. The argument `newshape` has inputs `batch_size`, `timesteps`,  `input_dim`. \n",
    "Note that `batch_size` = No of rows in `X_train` and `timesteps` = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RNN\n",
    "\n",
    "We make use of Keras, with a tensorflow backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now initialize RNN's as a sequnce of layers and add input and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM layers are added as follows with 50 memory units and input dimension with 1 feature. `return_sequences = True` is a required parameter that must be set to True when stacking two LSTM layers. A Dropout regularization of 20% is also added for each LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the LSTM layer\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding a second LSTM layer\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created 4 LSTM layers. Output layer is added with the `Dense` class with one-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complie the RNN, we use `rmsprop` optimizer and loss function chosen is MSE. The RNN is fit to the data for 100 epochs with a default `batch_size` of 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1198/1198 [==============================] - 30s - loss: 0.0390    \n",
      "Epoch 2/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0144    \n",
      "Epoch 3/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0117    \n",
      "Epoch 4/100\n",
      "1198/1198 [==============================] - 30s - loss: 0.0091    \n",
      "Epoch 5/100\n",
      "1198/1198 [==============================] - 30s - loss: 0.0091    \n",
      "Epoch 6/100\n",
      "1198/1198 [==============================] - 31s - loss: 0.0077    \n",
      "Epoch 7/100\n",
      "1198/1198 [==============================] - 30s - loss: 0.0078    \n",
      "Epoch 8/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0064    \n",
      "Epoch 9/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0076    \n",
      "Epoch 10/100\n",
      "1198/1198 [==============================] - 27s - loss: 0.0067    \n",
      "Epoch 11/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0065    \n",
      "Epoch 12/100\n",
      "1198/1198 [==============================] - 26s - loss: 0.0052    \n",
      "Epoch 13/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0057    \n",
      "Epoch 14/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0056    \n",
      "Epoch 15/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0048    \n",
      "Epoch 16/100\n",
      "1198/1198 [==============================] - 30s - loss: 0.0049    \n",
      "Epoch 17/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0047    \n",
      "Epoch 18/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0045    \n",
      "Epoch 19/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0044    \n",
      "Epoch 20/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0042    \n",
      "Epoch 21/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0037    \n",
      "Epoch 22/100\n",
      "1198/1198 [==============================] - 31s - loss: 0.0040    \n",
      "Epoch 23/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0038    \n",
      "Epoch 24/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0034    \n",
      "Epoch 25/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0039    \n",
      "Epoch 26/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0038    \n",
      "Epoch 27/100\n",
      "1198/1198 [==============================] - 30s - loss: 0.0035    \n",
      "Epoch 28/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0032    \n",
      "Epoch 29/100\n",
      "1198/1198 [==============================] - 31s - loss: 0.0039    \n",
      "Epoch 30/100\n",
      "1198/1198 [==============================] - 27s - loss: 0.0030    \n",
      "Epoch 31/100\n",
      "1198/1198 [==============================] - 30s - loss: 0.0030    \n",
      "Epoch 32/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0030    \n",
      "Epoch 33/100\n",
      "1198/1198 [==============================] - 30s - loss: 0.0031    \n",
      "Epoch 34/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0027    \n",
      "Epoch 35/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0028    \n",
      "Epoch 36/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0030    \n",
      "Epoch 37/100\n",
      "1198/1198 [==============================] - 27s - loss: 0.0030    \n",
      "Epoch 38/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0030    \n",
      "Epoch 39/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0030    \n",
      "Epoch 40/100\n",
      "1198/1198 [==============================] - 26s - loss: 0.0029    \n",
      "Epoch 41/100\n",
      "1198/1198 [==============================] - 41s - loss: 0.0028    \n",
      "Epoch 42/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0027    \n",
      "Epoch 43/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0027    \n",
      "Epoch 44/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0025    \n",
      "Epoch 45/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0028    \n",
      "Epoch 46/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0025    \n",
      "Epoch 47/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0027    \n",
      "Epoch 48/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0024    \n",
      "Epoch 49/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0023    \n",
      "Epoch 50/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0024    \n",
      "Epoch 51/100\n",
      "1198/1198 [==============================] - 313s - loss: 0.0027   \n",
      "Epoch 52/100\n",
      "1198/1198 [==============================] - 264s - loss: 0.0023   \n",
      "Epoch 53/100\n",
      "1198/1198 [==============================] - 27s - loss: 0.0025    \n",
      "Epoch 54/100\n",
      "1198/1198 [==============================] - 27s - loss: 0.0022    \n",
      "Epoch 55/100\n",
      "1198/1198 [==============================] - 26s - loss: 0.0024    \n",
      "Epoch 56/100\n",
      "1198/1198 [==============================] - 587s - loss: 0.0022   \n",
      "Epoch 57/100\n",
      "1198/1198 [==============================] - 240s - loss: 0.0023   \n",
      "Epoch 58/100\n",
      "1198/1198 [==============================] - 27s - loss: 0.0021    \n",
      "Epoch 59/100\n",
      "1198/1198 [==============================] - 26s - loss: 0.0022    \n",
      "Epoch 60/100\n",
      "1198/1198 [==============================] - 26s - loss: 0.0022    \n",
      "Epoch 61/100\n",
      "1198/1198 [==============================] - 825s - loss: 0.0022   \n",
      "Epoch 62/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0021    \n",
      "Epoch 63/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0020    \n",
      "Epoch 64/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0020    \n",
      "Epoch 65/100\n",
      "1198/1198 [==============================] - 27s - loss: 0.0022    \n",
      "Epoch 66/100\n",
      "1198/1198 [==============================] - 51s - loss: 0.0022    \n",
      "Epoch 67/100\n",
      "1198/1198 [==============================] - 57s - loss: 0.0018    \n",
      "Epoch 68/100\n",
      "1198/1198 [==============================] - 30s - loss: 0.0021    \n",
      "Epoch 69/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0019    \n",
      "Epoch 70/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0019    \n",
      "Epoch 71/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0019    \n",
      "Epoch 72/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0021    \n",
      "Epoch 73/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0021    \n",
      "Epoch 74/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0019    \n",
      "Epoch 75/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0019    \n",
      "Epoch 76/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0019    \n",
      "Epoch 77/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0018    \n",
      "Epoch 78/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0020    \n",
      "Epoch 79/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0018    \n",
      "Epoch 80/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0018    \n",
      "Epoch 81/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0018    \n",
      "Epoch 82/100\n",
      "1198/1198 [==============================] - 30s - loss: 0.0018    \n",
      "Epoch 83/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0016    \n",
      "Epoch 84/100\n",
      "1198/1198 [==============================] - 27s - loss: 0.0018    \n",
      "Epoch 85/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0018    \n",
      "Epoch 86/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0015    \n",
      "Epoch 87/100\n",
      "1198/1198 [==============================] - 27s - loss: 0.0017    \n",
      "Epoch 88/100\n",
      "1198/1198 [==============================] - 27s - loss: 0.0019    \n",
      "Epoch 89/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0017    \n",
      "Epoch 90/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0018    \n",
      "Epoch 91/100\n",
      "1198/1198 [==============================] - 202s - loss: 0.0017   \n",
      "Epoch 92/100\n",
      "1198/1198 [==============================] - 31s - loss: 0.0018    \n",
      "Epoch 93/100\n",
      "1198/1198 [==============================] - 30s - loss: 0.0017    \n",
      "Epoch 94/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0018    \n",
      "Epoch 95/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0016    \n",
      "Epoch 96/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0015    \n",
      "Epoch 97/100\n",
      "1198/1198 [==============================] - 29s - loss: 0.0016    \n",
      "Epoch 98/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0016    \n",
      "Epoch 99/100\n",
      "1198/1198 [==============================] - 28s - loss: 0.0016    \n",
      "Epoch 100/100\n",
      "1198/1198 [==============================] - 27s - loss: 0.0015    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124da3668>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the loss function has converged to a small value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions with timestep =60 can be tricky. The real Google Stock price is contained in the test set for January 2017. Also we need the entire data in one frame.i.e. from Jan 1st 2012 to Jan 31st 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the real stock price for January 1st 2012 - January 31st 2017\n",
    "dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the predicted stock price, we create an array of X_test , in a similar way we created X_train before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 80):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inverse scaling, `predicted_stock_price` will contain the predicted values for `real_stock_price`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets evaluate the RMSE for the the regression problem. RMSE should be expressed as percentage of `real_stock_price`(y_test). Generally a good rmse is below 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.8758650604492946"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = math.sqrt(mean_squared_error(real_stock_price, predicted_stock_price))\n",
    "(rmse/np.mean(real_stock_price))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the RMSE is more than 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now visualize the actual vs predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJghJUpUJQpJU9Rc0ly4PKsRjYQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1270fc128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concluding Remarks\n",
    "\n",
    "1. The predictive model for the Stock price predictions with an RMSE of 5.8% is obtained. \n",
    "2. The model seems to be good enough to capture the features of the dataset and in making predictions. Yet significant improvement can be brought by performing k-fold cross validation and hyperparameter tuning\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
